# 顺序锁

文章来源：http://www.wowotech.net/kernel_synchronization/seqlock.html

## 一、前言

普通的spin lock对待reader和writer是一视同仁，RW spin lock给reader赋予了更高的优先级，那么有没有让writer优先的锁的机制呢？答案就是seqlock。本文主要描述linux kernel 4.0中的seqlock的机制，首先是seqlock的工作原理，如果想浅尝辄止，那么了解了概念性的东东就OK了，也就是第二章了，当然，我还是推荐普通的驱动工程师了解seqlock的API，第三章给出了一个简单的例子，了解了这些，在驱动中 *（或者在其他内核模块）* 使用seqlock就可以易如反掌了。细节是魔鬼，概念性的东西需要天才的思考，不是说就代码实现的细节就无足轻重，如果想进入seqlock的内心世界，推荐阅读第四章seqlock的代码实现，这一章和cpu体系结构相关的内容我们选择了ARM64 *（呵呵～～要跟上时代的步伐）* 。最后一章是参考资料，如果觉得本文描述不清楚，可以参考这些经典文献，在无数不眠之夜，她们给我心灵的慰籍，也愿能够给读者带来快乐。

## 二、工作原理

seqlock这种锁机制是倾向writer thread，也就是说，除非有其他的writer thread进入了临界区，否则它会长驱直入，无论有多少的reader thread都不能阻挡writer的脚步。writer thread这么霸道，reader肿么办？对于seqlock，reader这一侧需要进行数据访问的过程中检测是否有并发的writer thread操作，如果检测到并发的writer，那么重新read。通过不断的retry，直到reader thread在临界区的时候，没有任何的writer thread插入即可。这样的设计对reader而言不是很公平，特别是如果writer thread负荷比较重的时候，reader thread可能会retry多次，从而导致reader thread这一侧性能的下降。

### seqlock的特点

临界区只允许一个writer thread进入，在没有writer thread的情况下，reader thread可以随意进入，也就是说reader不会阻挡reader。在临界区只有有reader thread的情况下，writer thread可以立刻执行，不会等待。

### writer的操作

对于writer thread，获取seqlock操作如下：

1. 获取锁 *（例如spin lock）* ，该锁确保临界区只有一个writer进入。

2. sequence counter加一

释放seqlock操作如下：

1. 释放锁，允许其他writer thread进入临界区。

2. sequence counter加一 *（注意不是减一哦，sequence counter是一个不断累加的counter）*

由上面的操作可知，如果临界区没有任何的writer thread，那么sequence counter是偶数 *（sequence counter初始化为0）* ，如果临界区有一个writer thread *（当然，也只能有一个）* ，那么sequence counter是奇数。

### reader的操作

1. 获取sequence counter的值，如果是偶数，可以进入临界区，如果是奇数，那么等待writer离开临界区 *（sequence counter变成偶数）* 。进入临界区时候的sequence counter的值我们称之old sequence counter。

2. 进入临界区，读取数据

3. 获取sequence counter的值，如果等于old sequence counter，说明一切OK，否则回到step 1

### 适用场景

一般而言，seqlock适用于：

1. read操作比较频繁

2. write操作较少，但是性能要求高，不希望被reader thread阻挡 *（之所以要求write操作较少主要是考虑read side的性能）*

3. 数据类型比较简单，但是数据的访问又无法利用原子操作来保护。

   我们举一个简单的例子来描述：假设需要保护的数据是一个链表，header--->A node--->B node--->C node--->null。reader thread遍历链表的过程中，将B node的指针赋给了临时变量x，这时候，中断发生了，reader thread被preempt *（注意，对于seqlock，reader并没有禁止抢占）* 。这样在其他cpu上执行的writer thread有充足的时间释放B node的memory *（注意：reader thread中的临时变量x还指向这段内存）* 。当read thread恢复执行，并通过x这个指针进行内存访问 *（例如试图通过next找到C node）*，悲剧发生了……

## 三、API示例

在kernel中，jiffies_64保存了从系统启动以来的tick数目，对该数据的访问 *（以及其他jiffies相关数据）* 需要持有`jiffies_lock`这个seq lock。

reader side代码如下：

```c
u64 get_jiffies_64(void)
{
    do {
        seq = read_seqbegin(&jiffies_lock);
        ret = jiffies_64;
    } while (read_seqretry(&jiffies_lock, seq));
}
```

可以看到这个示例中我们先调用`read_seqbegin`并存储它的返回值，用`read_seqretry`来判断这个返回值，从而确定是否在`read_seqbegin`到`read_seqretry`的临界段中成功获取了tick数。这个返回值显然就是sequence counter，在进入临界段和离开临界段时这个值没有变化，就说明临界段中没发生过write操作。换句话说，seq lock的read临界段可以被打断，并不是正真意义上的临界段哦。当然，我们的目标就是要让write能够打断read，只不过用了调度的方式来实现，所以read的API看起来并不像lock *（也不是真的lock）* 。这在API命名上也能看出来：没有命名成lock和unlock的形式。

writer side代码如下：

```c
static void tick_do_update_jiffies64(ktime_t now)
{
    write_seqlock(&jiffies_lock);
    临界区会修改jiffies_64等相关变量，具体代码略
    write_sequnlock(&jiffies_lock);
}
```

对照上面的代码，任何工程师都可以比着葫芦画瓢，使用seqlock来保护自己的临界区。当然，seqlock的接口API非常丰富，有兴趣的读者可以自行阅读seqlock.h文件。

## 四、实现

### 数据结构

```c
typedef struct {
    struct seqcount seqcount;  // sequence counter
    spinlock_t lock;
} seqlock_t;
```

可以看出来，seq lock实际上就是spin lock ＋ sequence counter。

### 实现细节

我们先来看看writer在进入临界段时调用的`write_seqlock`函数，它在include/linux/seqlock.h中。由于内部采用了spin lock来实现，write操作的临界段是不会被preempt的。
```c
static inline void write_seqlock(seqlock_t *sl)
{
    spin_lock(&sl->lock);
    sl->sequence++;
    smp_wmb();
}
```

唯一需要说明的是`smp_wmb`这个用于SMP场合下的写内存屏障，它确保了编译器以及CPU都不会打乱sequence counter内存访问以及临界区内存访问的顺序 *（临界区的保护是依赖sequence counter的值，因此不能打乱其顺序）* 。

再来看看同一个文件中的`write_sequnlock`：

```c
static inline void write_sequnlock(seqlock_t *sl)
{
    smp_wmb();
    s->sequence++;
    spin_unlock(&sl->lock);
}
```
非常简单，sequence counter++后释放spin lock。相比之下，`read_seqbegin`复杂不少

```c
static inline unsigned read_seqbegin(const seqlock_t *sl)
{ 
    unsigned ret;

    repeat:
        ret = ACCESS_ONCE(sl->sequence);  // 进入临界区之前，先要获取sequence counter的快照
        if (unlikely(ret & 1)) {  // 如果是奇数，说明有writer thread
            cpu_relax();
            goto repeat;  // 如果有writer，那么先不要进入临界区，不断的polling sequence counter
        }

    smp_rmb();  // 确保sequenc counter和临界区的内存访问顺序
    return ret;
}
```

如果有writer thread，`read_seqbegin`函数中会有一个不断polling sequenc counter，直到其变成偶数的过程，在这个过程中，如果不加以控制，那么整体系统的性能会有损失 *（这里的性能指的是功耗和速度）*。因此，在polling过程中，有一个`cpu_relax`的调用，对于ARM64，其代码是：

```c
static inline void cpu_relax(void)
{
    asm volatile("yield" ::: "memory");
}
```

`yield`指令用来告知硬件系统，本cpu上执行的指令是polling操作，没有那么急迫，如果有任何的资源冲突，本cpu可以让出控制权。对于ARM32，则并没有这个yield操作，仅仅执行smp_mb()来等待。

需要注意的是：

1. `read_seqbegin`函数在新的linux内核中已经舍弃了if-goto的形式，而是采用了while循环来实现。但是逻辑上是完全一致的。
2. `read_seqbegin`函数没有操作任何锁，只是用了原子操作来获取sequence counter的值，然后判断是否能进入临界区。直到能够进入临界区才退出循环。也就是说，它不会阻止write thread对共享资源的修改。这就是为什么第三章中的示例代码为什么需要写成循环的形式。
3. `read_seqbegin`函数有返回值，返回的是调用这个函数时读到的sequence counter的值，在`read_seqretry`时会用到它。

继续看read_seqretry的源码：

```c
static inline unsigned read_seqretry(const seqlock_t *sl, unsigned start)
{
    smp_rmb();  // 确保sequenc counter和临界区的内存访问顺序
    return unlikely(sl->sequence != start);
}
```
start参数就是进入临界区时候的sequence counter的快照，比对当前退出临界区的sequence counter，如果相等，说明没有writer进入打搅reader thread，那么可以愉快的离开临界区。

还有一个比较有意思的逻辑问题：`read_seqbegin`为何要进行奇偶判断？把一切都推到`read_seqretry`中进行判断不可以吗？也就是说，为何`read_seqbegin`要等到没有writer thread的情况下才进入临界区？其实有writer thread也可以进入，反正在`read_seqretry`中可以进行奇偶以及相等判断，从而保证逻辑的正确性。当然，这样想也是对的，不过在performance上有欠缺，reader在检测到有writer thread在临界区后，仍然放reader thread进入，可能会导致writer thread的一些额外的开销 *（cache miss）* ，因此，最好的方法是在read_seqbegin中拦截。

## 五、参考文献

- Understanding the Linux Kernel 3rd Edition

- Linux Kernel Development 3rd Edition

- Perfbook (https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html)